# Should we jit the main functions
jit_fn: True

# Seed for all random number generation and reproducibility of results
seed: 100

# Specify if the dynamics are known
known_dynamics: False

# Specify if the vehcile should be rendered
render: True

# What is this variable???
graph: False

# Control horizon
look_ahead_steps: 1


# Number of explorations step at the beginning of the episode
exploration_steps: null # None value -> Used the number of control inputs

# Exploration

# Discount factor
discount: 0.9

# Magnitude of the control values when doing excitation-based control
excitation_mag : 0.01

# The value of this key is a list.
# Each element in the list provides the necessary parameters to
# construct a LipschitzApproximator.
LipApprox:
  - lipschitzConstants: [0.0, 0.0, 0.0, 1.1, 0.0, 1.1, 0.0, 0.0, 0.0]
    boundsOnFunctionValues: [[-10.,10], [-10.,10], [-10.,10], [-10.,10], [-10.,10], [-10.,10],[-10.,10], [-10.,10], [-10.,10]]
    importanceWeights: [[0.,0.,1.], [0.,0.,1.],[0.,0.,1.], [0.,0.,1.],[0.,0.,1.], [0.,0.,1.],[0.,0.,1.], [0.,0.,1.],[0.,0.,1.]] # null # mean None
    maxDataSize: 50 # The maximum amount of data to stor for this approximator
    numStates: 3 # The number of imput states for this approximator
  # # If a second LipschitzApproximator is needed, it should be added too
  # - lipschitzConstants: list
  #   boundsOnFunctionValues: list of list with two elements or tuple
  #   importanceWeights: null or list of list
  #   maxDataSize: int
  #   numStates: int

# Parameters for computing the a priori enclosure
# These parameters must be taken such that the number of iterations
# in this loop is as small as possible
enclosure:
  fixpointWidenCoeff: 0.1
  zeroDiameter: 1.0e-5
  containTol: 1.0e-3
  maxFixpointIter: 5


# Parameters for the gradient-based optimizer
mpc_optimizer:
  # The maximum number of iterations
  max_iter: 500
  # Absolute tolerance as stopping criteria of the descent
  atol: 1.0e-8
  # Relative tolerance as stopping criteria of the descent
  rtol: 1.0e-8

  # Define the actual optimizer for the problem [This is an OPTAX-based optimizaton]
  optimizer:
    - name: scale_by_adam
      # params:
      #   b1: 0.999
      #   b2: 0.9999
    - name: exponential_decay
      scheduler: True
      params:
        # Initial learning rate (Negative value for minimization -> OPTAX format)
        init_value: -0.1
        # Basically the maximum number of gradient steps before constant step size
        # These values depends on the scheduler used -> check optax documentation
        transition_steps: 50000
        # Typically (end_value / init_value) if end_value is expected at end
        decay_rate: 0

  # My implementation of accelerated gradient descent with linesearch
  # optimizer:
  #   # The intial step size in case no linsearh arguments are provided
  #   stepsize: 1.

  #   # The maximum number of gradient updates
  #   max_iter: 15

  #   # The adaptive coefficient to scale the momentum. nill values mean
  #   # that it is not used and rather beta_k = k /(k+3) is used as classical acceleration momentum
  #   # This value should be between 0 and 1
  #   moment_scale: null

  #   # The initial momentum.
  #   beta_init: 0.25

  #   # The stoppng criteria of the algorithm based on gradient norm
  #   atol: 1.0e-3
  #   rtol: 1.0e-3

  #   linesearch:
  #     max_stepsize: 10. # The maximum admissible step size
  #     coef: 0.1 # The agressiveness coefficient. The smaller the larger step size in the optimization
  #     decrease_factor: 0.6 # The decrease factor when performing the armijo linesearch
  #     increase_factor: 1.4 # The increase factor at each new gradient descent iteration
  #     # # The reset strategy at each iteration
  #     # # "conservative": re-use previous stepsize, producing a non increasing sequence of stepsizes. Slow convergence.
  #     # # "increase": attempt to re-use previous stepsize multiplied by increase_factor. Cheap and efficient heuristic.
  #     reset_option: increase # or conservative
  #     maxls: 4 # Maximum number of iterations during the line search
